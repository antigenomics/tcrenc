{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161d9d6b-b307-4f57-8cd8-a7cd4007d6ab",
   "metadata": {},
   "source": [
    "# Peptides encoding (One-hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589cfceb-08c2-4c20-ac61-8f6e22499352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import peptides\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import seaborn as sns\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# libs for ml\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "#from umap import UMAP\n",
    "\n",
    "# my module with some func\n",
    "import pepcode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c79eb-16ae-4185-b04c-5afd0a64377b",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3433d2b8-0ae1-474a-a1ac-968eb7315591",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_LIST = pepcode.AA_LIST\n",
    "\n",
    "latent_dims = 200\n",
    "num_epochs = 500 \n",
    "batch_size = 300\n",
    "learning_rate = 1e-3 \n",
    "use_gpu = True\n",
    "\n",
    "# Device set\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif use_gpu and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f20ed-2bde-4e4e-835e-819bc46f4fe0",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1208dc8a-36be-4c1c-bcaa-feae6b26c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniconda3/envs/tcreppred_sil2/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./dataset/vdjdb-2024-11-27-fixed/vdjdb.slim.txt', sep = '\\t')\n",
    "data = data[(data.gene == 'TRB') & (data.species == 'HomoSapiens')]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "index_list = []\n",
    "for i in range(len(data)):\n",
    "    if len(data.iloc[i].cdr3)==15 and data.iloc[i].cdr3[0]=='C' and (data.iloc[i].cdr3[-1]=='F' or data.iloc[i].cdr3[-1]=='W'):\n",
    "        continue\n",
    "    else:\n",
    "        index_list.append(i)\n",
    "data.drop(index=index_list, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "# data.sample(frac=1, random_state=100).reset_index(drop=True, inplace=True)\n",
    "data = shuffle(data)\n",
    "\n",
    "#Split dataset and prepare train, test, evaluation datasets\n",
    "train_size, test_size, eval_size = int(round(len(data)*0.7, 0)), int(round(len(data)*(0.7+0.15), 0)), int(round(len(data)*(1), 0))\n",
    "data_split = np.split(data, [train_size, test_size, eval_size], axis=0)\n",
    "data_train = data_split[0]\n",
    "data_test = data_split[1]\n",
    "data_eval = data_split[2]\n",
    "\n",
    "# Prepare peptide lists\n",
    "pep_train_list = data_train.cdr3.values\n",
    "pep_test_list = data_test.cdr3.values\n",
    "pep_eval_list = data_eval.cdr3.values\n",
    "\n",
    "len_seq = len(pep_train_list[0])\n",
    "\n",
    "\n",
    "pep_train_oh = np.zeros((len(pep_train_list), len(pepcode.AA_LIST), len_seq), dtype = np.float32)\n",
    "for i in range(len(pep_train_oh)):\n",
    "    pep_train_oh[i] = pepcode.one_hot_code(pep_train_list[i])\n",
    "\n",
    "pep_test_oh = np.zeros((len(pep_test_list), len(pepcode.AA_LIST), len_seq), dtype = np.float32)\n",
    "for i in range(len(pep_test_list)):\n",
    "    pep_test_oh[i] = pepcode.one_hot_code(pep_test_list[i])   \n",
    "\n",
    "\n",
    "oh_matr_size = pep_test_oh[0].size\n",
    "\n",
    "# Пока не нужно\n",
    "pep_eval_oh = np.zeros((len(pep_eval_list), len(pepcode.AA_LIST), len_seq), dtype = np.float32)\n",
    "for i in range(len(pep_eval_list)):\n",
    "    pep_eval_oh[i] = pepcode.one_hot_code(pep_eval_list[i])  \n",
    "\n",
    "# Prepare train dataloader\n",
    "oh_dataset_train = torch.utils.data.TensorDataset(torch.tensor(pep_train_oh), torch.tensor(np.ones(pep_train_oh.shape[0])))\n",
    "oh_train_dl = torch.utils.data.DataLoader(oh_dataset_train, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Prepare test dataloader\n",
    "oh_dataset_test = torch.utils.data.TensorDataset(torch.tensor(pep_test_oh), torch.tensor(np.ones(pep_test_oh.shape[0])))\n",
    "oh_test_dl = torch.utils.data.DataLoader(oh_dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluation (пока не нужно)\n",
    "oh_dataset_eval = torch.utils.data.TensorDataset(torch.tensor(pep_eval_oh), torch.tensor(np.ones(pep_eval_oh.shape[0])))\n",
    "oh_eval_dl = torch.utils.data.DataLoader(oh_dataset_eval, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75cfec8-a978-4f43-84da-370ac38ed1e8",
   "metadata": {},
   "source": [
    "## Autoencoder definition (300->200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee309ece-c08c-4d27-bc77-fc3992f5029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters for One-hot encoding: 120500\n"
     ]
    }
   ],
   "source": [
    "autoencoder_arch = '300->200 without L2'\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=len(AA_LIST)*len_seq, out_features=latent_dims)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=latent_dims, out_features=len(AA_LIST)*len_seq)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        x_recon = self.decoder(latent)\n",
    "        return x_recon\n",
    "    \n",
    "autoencoder_f = Autoencoder()\n",
    "\n",
    "autoencoder_f = autoencoder_f.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in autoencoder_f.parameters() if p.requires_grad)\n",
    "print('Number of parameters for One-hot encoding: %d' % num_params)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder_f.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baedcf2d-f8ac-4266-b22e-1099ae595dc2",
   "metadata": {},
   "source": [
    "### Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db158561-ece0-4fb0-904b-a9948da977eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to training mode\n",
    "autoencoder_f.train()\n",
    "\n",
    "train_loss_avg_1 = []\n",
    "\n",
    "print('Training ...')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_avg_1.append(0)\n",
    "    num_batches = 0\n",
    "    \n",
    "    for pep_batch, _ in oh_train_dl:\n",
    "        \n",
    "        pep_batch = pep_batch.to(device)\n",
    "\n",
    "        pep_batch = pep_batch.reshape(-1, oh_matr_size)\n",
    "        \n",
    "        # autoencoder reconstruction\n",
    "        pep_batch_recon = autoencoder_f(pep_batch)\n",
    "        \n",
    "        # reconstruction error\n",
    "        loss = loss_function(pep_batch_recon, pep_batch)\n",
    "        \n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # one step of the optmizer (using the gradients from backpropagation)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_avg_1[-1] += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    train_loss_avg_1[-1] /= num_batches\n",
    "    if epoch % 50 == 0:\n",
    "        print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, num_epochs, train_loss_avg_1[-1]))\n",
    "print('Train finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55b16c-f15e-4e02-a794-5a9df1f6211d",
   "metadata": {},
   "source": [
    "### Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc6047-e8e3-403d-abd2-763f422c5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_f.eval()\n",
    "\n",
    "output = []\n",
    "test_loss_avg_1, num_batches = 0, 0\n",
    "\n",
    "# Прогоняем тестовую выборку через автоэнкодер\n",
    "for (pep, _) in oh_test_dl:\n",
    "    with torch.no_grad():\n",
    "        pep = pep.reshape(-1, oh_matr_size)\n",
    "        pep = pep.to(device)\n",
    "        pep_recon = autoencoder_f(pep)\n",
    "        loss = loss_function(pep_recon, pep)\n",
    "        test_loss_avg_1 += loss.item()\n",
    "        num_batches += 1\n",
    "    output.append((pep, pep_recon))\n",
    "test_loss_avg_1 /= num_batches\n",
    "\n",
    "\n",
    "test_loss_avg_1 /= num_batches\n",
    "print('Average reconstruction error: %f' % (test_loss_avg_1))\n",
    "\n",
    "# Output выглядит странно это лист, состоящий из кортежей, каждый из которых относится к одному батчу. Т.е. ouput[0] - это кортеж из первого батча\n",
    "# Далее каждый кортеж, состоит из двух тензоров: до и после энкодера. Тензоры в 2д формате.\n",
    "\n",
    "\n",
    "# Создаём пустые(нулевые) массивы для one-hot петпидов до и после\n",
    "pep_test_oh_bef = np.zeros((len(pep_test_list), len(pepcode.AA_LIST), len_seq), dtype = np.float32)\n",
    "pep_test_oh_aft = np.zeros((len(pep_test_list), len(pepcode.AA_LIST), len_seq), dtype = np.float32)\n",
    "\n",
    "\n",
    "# Переводим пептиды в np массив из output\n",
    "pointer = 0\n",
    "for i in range(num_batches):\n",
    "    cur_batch_size = len(output[i][0])\n",
    "    pep_test_oh_bef[pointer:pointer + cur_batch_size, :, : ] = output[i][0].reshape((cur_batch_size, len(AA_LIST), len_seq)).numpy(force=True)\n",
    "    pep_test_oh_aft[pointer:pointer + cur_batch_size, :, : ] = output[i][1].reshape((cur_batch_size, len(AA_LIST), len_seq)).numpy(force=True)\n",
    "    pointer += cur_batch_size\n",
    "    \n",
    "\n",
    "# Для каждого пептида после автоэнкодера приводим его к формату one-hot путем простанови 1 на место максимального веса в столбце\n",
    "for i in range(pep_test_oh_aft.shape[0]):\n",
    "    for j in range(len_seq):\n",
    "        col_max = np.max(pep_test_oh_aft[i][:,j])\n",
    "        for k in range(len(AA_LIST)):\n",
    "            if pep_test_oh_aft[i][k][j] == col_max:\n",
    "                pep_test_oh_aft[i][k][j] = 1.0\n",
    "            else: \n",
    "                pep_test_oh_aft[i][k][j] = 0.0  \n",
    "\n",
    "pep_test_list_bef_ae = []\n",
    "pep_test_list_aft_ae = []\n",
    "\n",
    "for i in range(pep_test_oh_aft.shape[0]):\n",
    "    pep_test_list_bef_ae.append(pepcode.one_hot_decode(pep_test_oh_bef[i]))   \n",
    "    pep_test_list_aft_ae.append(pepcode.one_hot_decode(pep_test_oh_aft[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b9a86-98e6-40d4-9df1-e6aa63439544",
   "metadata": {},
   "source": [
    "#### Biological evaluatiuon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c30289c-14d9-4e60-87fe-1d063dbdd96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_count = np.zeros(len_seq, dtype = np.float32)\n",
    "blos_score = np.zeros(len_seq, dtype = np.float32)\n",
    "\n",
    "for i in range(len(pep_test_list_bef_ae)):\n",
    "    for j in range(len_seq):\n",
    "        if pep_test_list_bef_ae[i][j] != pep_test_list_aft_ae[i][j]:\n",
    "            err_count[j] +=1\n",
    "            blos_score[j] += pepcode.blosum_score(pep_test_list_bef_ae[i][j],pep_test_list_aft_ae[i][j])\n",
    "\n",
    "\n",
    "avg_blos_score = {}\n",
    "for i in range(len_seq):\n",
    "    if err_count[i] !=0:\n",
    "        avg_blos_score[i]=blos_score[i]/err_count[i]\n",
    "\n",
    "pep_test_list_bef_ae_aa = []\n",
    "pep_test_list_aft_ae_aa = []\n",
    "for i in range(len(pep_test_list_bef_ae)):\n",
    "    for j in pep_test_list_bef_ae[i]:\n",
    "        pep_test_list_bef_ae_aa.append(j)\n",
    "    for k in pep_test_list_aft_ae[i]:\n",
    "        pep_test_list_aft_ae_aa.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bdd83-a951-484e-90da-7208272539f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,2, figsize = [8.3, 11.7])\n",
    "\n",
    "sns.pointplot(train_loss_avg_1 , color = 'green', ax=axs[0, 0])\n",
    "sns.pointplot(x=avg_blos_score.keys(), y=avg_blos_score.values(), color='green', ax=axs[1,0])\n",
    "sns.pointplot(err_count, color = 'green', ax=axs[2, 0])\n",
    "sns.pointplot(err_count/len(pep_test_list_bef_ae), color = 'green', ax=axs[2, 1])\n",
    "axs[0, 0].hlines(round(test_loss_avg_1, 5), 0, num_epochs, color = 'red', label='Test MSE')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].set(xlabel='Epoch', ylabel='Reconstruction error', title = f'Reconstruction error during training\\n for Autoencoder_final', xticks=[i for i in range(1, num_epochs, int(num_epochs/10))])\n",
    "axs[0, 1].set(frame_on=False)\n",
    "axs[0, 1].set_xticks([])\n",
    "axs[0, 1].set_yticks([])\n",
    "axs[0, 1].text(x=-0.1, y=-1.5, s=f'Average reconstruction error on test set:\\nMSE: {round(test_loss_avg_1, 5)}\\nRMSE: {round(sqrt(test_loss_avg_1), 5)}\\n\\nArchitecture: {autoencoder_arch}\\nLearning rate: {learning_rate}\\n\\n{classification_report(pep_test_list_bef_ae_aa, pep_test_list_aft_ae_aa)}')\n",
    "axs[1, 0].set(xlabel='Position in peptide', ylabel='Average blossum62 score', title=f'Average blossum62 score by position for\\nAutoencoder_final')\n",
    "axs[1, 1].set(frame_on=False)\n",
    "axs[1, 1].set_xticks([])\n",
    "axs[1, 1].set_yticks([])\n",
    "axs[2, 0].set(xlabel='Position in peptide', ylabel='Count of errors', title=f'Count of errors by position\\n for Autoencoder_final')\n",
    "axs[2, 1].set(xlabel='Position in peptide', ylabel='Percent of errors', title=f'Count of errors by position\\n  for Autoencoder_final(in %)', yticks=[i/10 for i in range(1, 10)])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "fig.suptitle(f'One-hot Encoder with arch {autoencoder_arch} on test set') \n",
    "plt.show()\n",
    "fig.savefig(f'./Results_one_hot/{str(date.today())}_final_{autoencoder_arch}_on_test.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d4b2a-fa3b-4add-b388-8064fa4a3df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4381d909-e69b-4009-a93c-3060301edbd4",
   "metadata": {},
   "source": [
    "### Evaluation on eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2eb077-ab91-48c1-b847-cbc88bd5614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_f.eval()\n",
    "\n",
    "output = []\n",
    "eval_loss_avg_1, num_batches = 0, 0\n",
    "\n",
    "# Прогоняем тестовую выборку через автоэнкодер\n",
    "for (pep, _) in oh_eval_dl:\n",
    "    with torch.no_grad():\n",
    "        pep = pep.reshape(-1, oh_matr_size)\n",
    "        pep = pep.to(device)\n",
    "        pep_recon = autoencoder_f(pep)\n",
    "        loss = loss_function(pep_recon, pep)\n",
    "        eval_loss_avg_1 += loss.item()\n",
    "        num_batches += 1\n",
    "    output.append((pep, pep_recon))\n",
    "eval_loss_avg_1 /= num_batches\n",
    "\n",
    "\n",
    "eval_loss_avg_1 /= num_batches\n",
    "print('Average reconstruction error: %f' % (eval_loss_avg_1))\n",
    "\n",
    "# Output выглядит странно это лист, состоящий из кортежей, каждый из которых относится к одному батчу. Т.е. ouput[0] - это кортеж из первого батча\n",
    "# Далее каждый кортеж, состоит из двух тензоров: до и после энкодера. Тензоры в 2д формате.\n",
    "\n",
    "\n",
    "# Создаём пустые(нулевые) массивы для one-hot петпидов до и после\n",
    "pep_eval_oh_bef = np.zeros((len(pep_eval_list), len(pepcode.AA_LIST), len_seq), dtype = np.float32)\n",
    "pep_eval_oh_aft = np.zeros((len(pep_eval_list), len(pepcode.AA_LIST), len_seq), dtype = np.float32)\n",
    "\n",
    "\n",
    "# Переводим пептиды в np массив из output\n",
    "pointer = 0\n",
    "for i in range(num_batches):\n",
    "    cur_batch_size = len(output[i][0])\n",
    "    pep_eval_oh_bef[pointer:pointer + cur_batch_size, :, : ] = output[i][0].reshape((cur_batch_size, len(AA_LIST), len_seq)).numpy(force=True)\n",
    "    pep_eval_oh_aft[pointer:pointer + cur_batch_size, :, : ] = output[i][1].reshape((cur_batch_size, len(AA_LIST), len_seq)).numpy(force=True)\n",
    "    pointer += cur_batch_size\n",
    "    \n",
    "\n",
    "# Для каждого пептида после автоэнкодера приводим его к формату one-hot путем простанови 1 на место максимального веса в столбце\n",
    "for i in range(pep_eval_oh_aft.shape[0]):\n",
    "    for j in range(len_seq):\n",
    "        col_max = np.max(pep_eval_oh_aft[i][:,j])\n",
    "        for k in range(len(AA_LIST)):\n",
    "            if pep_eval_oh_aft[i][k][j] == col_max:\n",
    "                pep_eval_oh_aft[i][k][j] = 1.0\n",
    "            else: \n",
    "                pep_eval_oh_aft[i][k][j] = 0.0  \n",
    "\n",
    "pep_eval_list_bef_ae = []\n",
    "pep_eval_list_aft_ae = []\n",
    "\n",
    "for i in range(pep_eval_oh_aft.shape[0]):\n",
    "    pep_eval_list_bef_ae.append(pepcode.one_hot_decode(pep_eval_oh_bef[i]))   \n",
    "    pep_eval_list_aft_ae.append(pepcode.one_hot_decode(pep_eval_oh_aft[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3122623-7b13-4bfc-8f27-9e15c1b502a6",
   "metadata": {},
   "source": [
    "### Biological evaluatiuon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed586f97-f9d9-4ab2-8039-c975e630497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_count = np.zeros(len_seq, dtype = np.float32)\n",
    "blos_score = np.zeros(len_seq, dtype = np.float32)\n",
    "\n",
    "for i in range(len(pep_eval_list_bef_ae)):\n",
    "    for j in range(len_seq):\n",
    "        if pep_eval_list_bef_ae[i][j] != pep_eval_list_aft_ae[i][j]:\n",
    "            err_count[j] +=1\n",
    "            blos_score[j] += pepcode.blosum_score(pep_eval_list_bef_ae[i][j],pep_eval_list_aft_ae[i][j])\n",
    "\n",
    "\n",
    "avg_blos_score = {}\n",
    "for i in range(len_seq):\n",
    "    if err_count[i] !=0:\n",
    "        avg_blos_score[i]=blos_score[i]/err_count[i]\n",
    "\n",
    "pep_eval_list_bef_ae_aa = []\n",
    "pep_eval_list_aft_ae_aa = []\n",
    "for i in range(len(pep_eval_list_bef_ae)):\n",
    "    for j in pep_eval_list_bef_ae[i]:\n",
    "        pep_eval_list_bef_ae_aa.append(j)\n",
    "    for k in pep_eval_list_aft_ae[i]:\n",
    "        pep_eval_list_aft_ae_aa.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d284bae-3e79-4f46-91e2-eab50519c867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,2, figsize = [8.3, 11.7])\n",
    "\n",
    "# sns.pointplot(train_loss_avg_1 , color = 'green', ax=axs[0, 0])\n",
    "sns.pointplot(x=avg_blos_score.keys(), y=avg_blos_score.values(), color='green', ax=axs[1,0])\n",
    "sns.pointplot(err_count, color = 'green', ax=axs[2, 0])\n",
    "sns.pointplot(err_count/len(pep_eval_list_bef_ae), color = 'green', ax=axs[2, 1])\n",
    "axs[0, 0].hlines(round(eval_loss_avg_1, 5), 0, num_epochs, color = 'red', label='Eval MSE')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].set(xlabel='Epoch', ylabel='Reconstruction error', title = f'Reconstruction error during training\\n for Autoencoder_final', xticks=[i for i in range(1, num_epochs, int(num_epochs/10))])\n",
    "axs[0, 1].set(frame_on=False)\n",
    "axs[0, 1].set_xticks([])\n",
    "axs[0, 1].set_yticks([])\n",
    "axs[0, 1].text(x=-0.1, y=-1.5, s=f'Average reconstruction error on evaluation set:\\nMSE: {round(eval_loss_avg_1, 5)}\\nRMSE: {round(sqrt(eval_loss_avg_1), 5)}\\n\\nArchitecture: {autoencoder_arch}\\nLearning rate: {learning_rate}\\n\\n{classification_report(pep_eval_list_bef_ae_aa, pep_eval_list_aft_ae_aa)}')\n",
    "axs[1, 0].set(xlabel='Position in peptide', ylabel='Average blossum62 score', title=f'Average blossum62 score by position for\\nAutoencoder_final')\n",
    "axs[1, 1].set(frame_on=False)\n",
    "axs[1, 1].set_xticks([])\n",
    "axs[1, 1].set_yticks([])\n",
    "axs[2, 0].set(xlabel='Position in peptide', ylabel='Count of errors', title=f'Count of errors by position\\n for Autoencoder_final')\n",
    "axs[2, 1].set(xlabel='Position in peptide', ylabel='Percent of errors', title=f'Count of errors by position\\n  for Autoencoder_final(in %)', yticks=[i/10 for i in range(1, 10)])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "fig.suptitle(f'One-hot Encoder with arch {autoencoder_arch} on evaluation set') \n",
    "plt.show()\n",
    "# fig.savefig(f'./Results_one_hot/{str(date.today())}_final_{autoencoder_arch}_on_eval.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbea9a2-9b9d-42b4-93bb-2000d4d3d09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73ded507-ae57-4dd6-a583-5f759d812d9b",
   "metadata": {},
   "source": [
    "### Model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfffe8-f67e-4775-acca-cc8c5b9d87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder_f, f'One-hot_models/model_f.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f7d87-2aba-42ed-b90a-25b4bee19fbc",
   "metadata": {},
   "source": [
    "## Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd621c47-d88f-4359-8990-809ff0733f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./One-hot_models/model_f.pth', weights_only=False) # Class should be defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8eea3-d8be-48cd-933e-bd1ed6ad31f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b84bd0-5da6-4635-9410-2ded1d9247e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = []\n",
    "num_batches = 0\n",
    "\n",
    "# Прогоняем тестовую выборку через энкодер\n",
    "for (pep, _) in oh_eval_dl:\n",
    "    with torch.no_grad():\n",
    "        pep = pep.reshape(-1, oh_matr_size)\n",
    "        pep = pep.to(device)\n",
    "        pep_recon = model.encoder(pep)\n",
    "        num_batches += 1\n",
    "    output.append((pep, pep_recon))\n",
    "\n",
    "output\n",
    "\n",
    "\n",
    "# Создаём пустые(нулевые) массивы для one-hot петпидов до и после\n",
    "pep_eval_oh_bef = np.zeros((len(pep_eval_list), len(pepcode.AA_LIST), len_seq), dtype = np.float32)\n",
    "pep_eval_oh_encoded = np.zeros((len(pep_eval_list), 200), dtype = np.float32)\n",
    "\n",
    "\n",
    "# Переводим пептиды в np массив из output\n",
    "pointer = 0\n",
    "for i in range(num_batches):\n",
    "    cur_batch_size = len(output[i][0])\n",
    "    pep_eval_oh_bef[pointer:pointer + cur_batch_size, :, : ] = output[i][0].reshape((cur_batch_size, len(AA_LIST), len_seq)).numpy(force=True)\n",
    "    pep_eval_oh_encoded[pointer:pointer + cur_batch_size, : ] = output[i][1].reshape((cur_batch_size, 200)).numpy(force=True)\n",
    "    pointer += cur_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a602365-2a0a-4fab-b505-33b9d4b38c2a",
   "metadata": {},
   "source": [
    "## Biological sense (Пока не доделано)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0ba42-949a-43d6-b517-1a57c62e99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пока не важно\n",
    "for i in range(data_eval['v.segm'].size):\n",
    "    data_eval['v.segm'].iloc[i] = data_eval['v.segm'].iloc[i].split('*')[0]\n",
    "    data_eval['j.segm'].iloc[i] = data_eval['j.segm'].iloc[i].split('*')[0]\n",
    "\n",
    "# data_eval['v.segm']\n",
    "\n",
    "# fig, axs = plt.subplots(4,2, figsize = [8.3, 11.7])\n",
    "# perplexity_list = [0.1, 1, 5, 10, 20, 50, 100, 1000]\n",
    "\n",
    "# for i in range(len(perplexity_list)):\n",
    "#     tsne = TSNE(n_components=2, n_jobs=-1,\n",
    "#                 n_iter=500, perplexity=perplexity_list[i])\n",
    "#     data_tsne = tsne.fit_transform(pep_eval_oh_encoded)\n",
    "#     sns.scatterplot(x=data_tsne [:, 0],\n",
    "#                     y=data_tsne [:, 1],\n",
    "#                     hue = data_eval['antigen.species'].values.reshape(-1),\n",
    "#                     palette=\"colorblind\", ax=axs[int(i%(len(perplexity_list)/2)), int(i//(len(perplexity_list)/2))])\n",
    "#     axs[int(i%(len(perplexity_list)/2)), int(i//(len(perplexity_list)/2))].set(xlabel='TSNE_1', ylabel='TSNE_2', title=f'TSNE for encoded peptides\\nwith perplexity={perplexity_list[i]}')\n",
    "#     axs[int(i%(len(perplexity_list)/2)), int(i//(len(perplexity_list)/2))].legend().set_visible(False)\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcreppred_sil2",
   "language": "python",
   "name": "tcreppred_sil2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
